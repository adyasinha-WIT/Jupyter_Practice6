# Jupyter_Practice6

In this project, I have practiced Dimensionality Reduction and Clustering. These techniques are used to reduce the number of variables and to create clusters based similarities, respectively.

**Principal Component Analysis (PCA)** is linear dimensionality reduction technique that transforms data into a new coordinate system by finding the directions (principal components) that maximize variance.
**t-Distributed Stochastic Neighbor Embedding (t-SNE)** is a non-linear dimensionality reduction technique that focuses on preserving the local structure of the data, converting high-dimensional Euclidean distances into conditional probabilities.
**Linear Discriminant Analysis (LDA)** is a generalization of Fisher's linear discriminant, a method used in statistics and other fields, to find a linear combination of features that characterizes or separates two or more classes of objects or events.
**k-Means Clustering** is a unsupervised method that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster.
